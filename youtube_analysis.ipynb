{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>public</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@aqueminteressarpossa</td>\n",
       "      <td>2024-06-05T22:14:26Z</td>\n",
       "      <td>0</td>\n",
       "      <td>N√£o conhecia seu canal e amei sua personalidad...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['conhecia', 'canal', 'amei', 'personalidade',...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@alexiafonsecacordeiro1482</td>\n",
       "      <td>2024-05-23T14:00:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Eu amo v√≠deos longos. E traz maiiissss</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['amo', 'vamos', 'longos', 'traz', 'maiiissss']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ateliegirassol2204</td>\n",
       "      <td>2024-05-17T00:22:51Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Me julguem, achei o blush lindo na sua pele. N...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['julguem', 'achei', 'blusa', 'lindo', 'pele',...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@resenhassonsasaleatorias</td>\n",
       "      <td>2024-05-04T13:02:29Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Realmente na pele negra n√£o rola...comprei o p...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['realmente', 'pele', 'negra', 'rolacomprei', ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@laryssamessias5987</td>\n",
       "      <td>2024-04-16T09:38:56Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Eu sou negra, gosto do contorno e do blush she...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['negra', 'gosto', 'contorno', 'blusa', 'chega...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>@roseane_mundo</td>\n",
       "      <td>2017-04-21T12:20:24Z</td>\n",
       "      <td>52</td>\n",
       "      <td>Eu amo a base da L'Or√©al. A MAC √© queridinha. ...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['amo', 'base', 'moral', 'queridinha', 'mandom...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>@memphiiis</td>\n",
       "      <td>2017-04-21T12:15:41Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Ol√° T√°ssio, estou amando seus v√≠deos e acho qu...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ol', 'seio', 'amando', 'vamos', 'acho', 'so'...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>@martinabevi</td>\n",
       "      <td>2017-04-21T12:14:36Z</td>\n",
       "      <td>1</td>\n",
       "      <td>ouvi dizer que a da pausa para feminices √© boa!</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ouvi', 'dizer', 'pausa', 'feminis', 'boa']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>@HerdeiradaBeleza</td>\n",
       "      <td>2017-04-21T12:08:10Z</td>\n",
       "      <td>176</td>\n",
       "      <td>Me mostrem um pouco de amor no Instagram! üíó O ...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['mostrei', 'pouco', 'amor', 'instaram', 'herd...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>@thaisduarte1062</td>\n",
       "      <td>2017-04-21T12:03:16Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Ameeeeiiii</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ameeeeiiii']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5287 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          author            updated_at  like_count  \\\n",
       "0          @aqueminteressarpossa  2024-06-05T22:14:26Z           0   \n",
       "1     @alexiafonsecacordeiro1482  2024-05-23T14:00:30Z           1   \n",
       "2            @ateliegirassol2204  2024-05-17T00:22:51Z           0   \n",
       "3      @resenhassonsasaleatorias  2024-05-04T13:02:29Z           0   \n",
       "4            @laryssamessias5987  2024-04-16T09:38:56Z           0   \n",
       "...                          ...                   ...         ...   \n",
       "5282              @roseane_mundo  2017-04-21T12:20:24Z          52   \n",
       "5283                  @memphiiis  2017-04-21T12:15:41Z           1   \n",
       "5284                @martinabevi  2017-04-21T12:14:36Z           1   \n",
       "5285           @HerdeiradaBeleza  2017-04-21T12:08:10Z         176   \n",
       "5286            @thaisduarte1062  2017-04-21T12:03:16Z           1   \n",
       "\n",
       "                                                   text     video_id  public  \\\n",
       "0     N√£o conhecia seu canal e amei sua personalidad...  nxdjgqKkOlI    True   \n",
       "1                Eu amo v√≠deos longos. E traz maiiissss  nxdjgqKkOlI    True   \n",
       "2     Me julguem, achei o blush lindo na sua pele. N...  nxdjgqKkOlI    True   \n",
       "3     Realmente na pele negra n√£o rola...comprei o p...  nxdjgqKkOlI    True   \n",
       "4     Eu sou negra, gosto do contorno e do blush she...  nxdjgqKkOlI    True   \n",
       "...                                                 ...          ...     ...   \n",
       "5282  Eu amo a base da L'Or√©al. A MAC √© queridinha. ...  raV8DpfwuR0    True   \n",
       "5283  Ol√° T√°ssio, estou amando seus v√≠deos e acho qu...  raV8DpfwuR0    True   \n",
       "5284    ouvi dizer que a da pausa para feminices √© boa!  raV8DpfwuR0    True   \n",
       "5285  Me mostrem um pouco de amor no Instagram! üíó O ...  raV8DpfwuR0    True   \n",
       "5286                                         Ameeeeiiii  raV8DpfwuR0    True   \n",
       "\n",
       "                                                 tokens  word_count  \n",
       "0     ['conhecia', 'canal', 'amei', 'personalidade',...          14  \n",
       "1       ['amo', 'vamos', 'longos', 'traz', 'maiiissss']           5  \n",
       "2     ['julguem', 'achei', 'blusa', 'lindo', 'pele',...           9  \n",
       "3     ['realmente', 'pele', 'negra', 'rolacomprei', ...          14  \n",
       "4     ['negra', 'gosto', 'contorno', 'blusa', 'chega...          17  \n",
       "...                                                 ...         ...  \n",
       "5282  ['amo', 'base', 'moral', 'queridinha', 'mandom...          17  \n",
       "5283  ['ol', 'seio', 'amando', 'vamos', 'acho', 'so'...          39  \n",
       "5284       ['ouvi', 'dizer', 'pausa', 'feminis', 'boa']           5  \n",
       "5285  ['mostrei', 'pouco', 'amor', 'instaram', 'herd...           5  \n",
       "5286                                     ['ameeeeiiii']           1  \n",
       "\n",
       "[5287 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/youtube_comments.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>public</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N√£o conhecia seu canal e amei sua personalidad...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['conhecia', 'canal', 'amei', 'personalidade',...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Eu amo v√≠deos longos. E traz maiiissss</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['amo', 'vamos', 'longos', 'traz', 'maiiissss']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Me julguem, achei o blush lindo na sua pele. N...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['julguem', 'achei', 'blusa', 'lindo', 'pele',...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Realmente na pele negra n√£o rola...comprei o p...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['realmente', 'pele', 'negra', 'rolacomprei', ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Eu sou negra, gosto do contorno e do blush she...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['negra', 'gosto', 'contorno', 'blusa', 'chega...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>52</td>\n",
       "      <td>Eu amo a base da L'Or√©al. A MAC √© queridinha. ...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['amo', 'base', 'moral', 'queridinha', 'mandom...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>1</td>\n",
       "      <td>Ol√° T√°ssio, estou amando seus v√≠deos e acho qu...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ol', 'seio', 'amando', 'vamos', 'acho', 'so'...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>1</td>\n",
       "      <td>ouvi dizer que a da pausa para feminices √© boa!</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ouvi', 'dizer', 'pausa', 'feminis', 'boa']</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>176</td>\n",
       "      <td>Me mostrem um pouco de amor no Instagram! üíó O ...</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['mostrei', 'pouco', 'amor', 'instaram', 'herd...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>1</td>\n",
       "      <td>Ameeeeiiii</td>\n",
       "      <td>raV8DpfwuR0</td>\n",
       "      <td>True</td>\n",
       "      <td>['ameeeeiiii']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5287 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      like_count                                               text  \\\n",
       "0              0  N√£o conhecia seu canal e amei sua personalidad...   \n",
       "1              1             Eu amo v√≠deos longos. E traz maiiissss   \n",
       "2              0  Me julguem, achei o blush lindo na sua pele. N...   \n",
       "3              0  Realmente na pele negra n√£o rola...comprei o p...   \n",
       "4              0  Eu sou negra, gosto do contorno e do blush she...   \n",
       "...          ...                                                ...   \n",
       "5282          52  Eu amo a base da L'Or√©al. A MAC √© queridinha. ...   \n",
       "5283           1  Ol√° T√°ssio, estou amando seus v√≠deos e acho qu...   \n",
       "5284           1    ouvi dizer que a da pausa para feminices √© boa!   \n",
       "5285         176  Me mostrem um pouco de amor no Instagram! üíó O ...   \n",
       "5286           1                                         Ameeeeiiii   \n",
       "\n",
       "         video_id  public                                             tokens  \\\n",
       "0     nxdjgqKkOlI    True  ['conhecia', 'canal', 'amei', 'personalidade',...   \n",
       "1     nxdjgqKkOlI    True    ['amo', 'vamos', 'longos', 'traz', 'maiiissss']   \n",
       "2     nxdjgqKkOlI    True  ['julguem', 'achei', 'blusa', 'lindo', 'pele',...   \n",
       "3     nxdjgqKkOlI    True  ['realmente', 'pele', 'negra', 'rolacomprei', ...   \n",
       "4     nxdjgqKkOlI    True  ['negra', 'gosto', 'contorno', 'blusa', 'chega...   \n",
       "...           ...     ...                                                ...   \n",
       "5282  raV8DpfwuR0    True  ['amo', 'base', 'moral', 'queridinha', 'mandom...   \n",
       "5283  raV8DpfwuR0    True  ['ol', 'seio', 'amando', 'vamos', 'acho', 'so'...   \n",
       "5284  raV8DpfwuR0    True       ['ouvi', 'dizer', 'pausa', 'feminis', 'boa']   \n",
       "5285  raV8DpfwuR0    True  ['mostrei', 'pouco', 'amor', 'instaram', 'herd...   \n",
       "5286  raV8DpfwuR0    True                                     ['ameeeeiiii']   \n",
       "\n",
       "      word_count  \n",
       "0             14  \n",
       "1              5  \n",
       "2              9  \n",
       "3             14  \n",
       "4             17  \n",
       "...          ...  \n",
       "5282          17  \n",
       "5283          39  \n",
       "5284           5  \n",
       "5285           5  \n",
       "5286           1  \n",
       "\n",
       "[5287 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluir as colunas 'author' e 'updated_at'\n",
    "df = df.drop(['author', 'updated_at'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar a Ocorr√™ncia e Frequ√™ncia de Termos Espec√≠ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequ√™ncia de termos espec√≠ficos: {'base': 1504, 'pele': 1226, 'negra': 785, 'dificuldade': 61, 'cor': 430, 'ruim': 40, 'dif√≠cil': 110, 'pele negra': 0}\n"
     ]
    }
   ],
   "source": [
    "specific_terms = ['base', 'pele', 'negra', 'dificuldade', 'cor', 'ruim', 'dif√≠cil', 'pele negra']\n",
    "\n",
    "def term_frequency(df, terms):\n",
    "    term_freq = {term: 0 for term in terms}\n",
    "    for tokens in df['tokens']:\n",
    "        tokens_list = eval(tokens)  # Converter a string de lista para uma lista real\n",
    "        for term in terms:\n",
    "            term_freq[term] += tokens_list.count(term)\n",
    "    return term_freq\n",
    "\n",
    "term_freq = term_frequency(df, specific_terms)\n",
    "print(\"Frequ√™ncia de termos espec√≠ficos:\", term_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An√°lise de Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\laura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para analisar o sentimento a partir do texto\n",
    "def analisar_sentimento_text(texto):\n",
    "    score = sentiment_analyzer.polarity_scores(texto)\n",
    "    return score['compound']\n",
    "\n",
    "# Fun√ß√£o para analisar o sentimento a partir dos tokens\n",
    "def analisar_sentimento_tokens(tokens):\n",
    "    tokens_list = eval(tokens)  # Converter a string de lista para uma lista real\n",
    "    texto = ' '.join(tokens_list)  # Converter tokens para texto\n",
    "    score = sentiment_analyzer.polarity_scores(texto)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>public</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentimento_text</th>\n",
       "      <th>sentimento_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N√£o conhecia seu canal e amei sua personalidad...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['conhecia', 'canal', 'amei', 'personalidade',...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Eu amo v√≠deos longos. E traz maiiissss</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['amo', 'vamos', 'longos', 'traz', 'maiiissss']</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Me julguem, achei o blush lindo na sua pele. N...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['julguem', 'achei', 'blusa', 'lindo', 'pele',...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Realmente na pele negra n√£o rola...comprei o p...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['realmente', 'pele', 'negra', 'rolacomprei', ...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Eu sou negra, gosto do contorno e do blush she...</td>\n",
       "      <td>nxdjgqKkOlI</td>\n",
       "      <td>True</td>\n",
       "      <td>['negra', 'gosto', 'contorno', 'blusa', 'chega...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   like_count                                               text     video_id  \\\n",
       "0           0  N√£o conhecia seu canal e amei sua personalidad...  nxdjgqKkOlI   \n",
       "1           1             Eu amo v√≠deos longos. E traz maiiissss  nxdjgqKkOlI   \n",
       "2           0  Me julguem, achei o blush lindo na sua pele. N...  nxdjgqKkOlI   \n",
       "3           0  Realmente na pele negra n√£o rola...comprei o p...  nxdjgqKkOlI   \n",
       "4           0  Eu sou negra, gosto do contorno e do blush she...  nxdjgqKkOlI   \n",
       "\n",
       "   public                                             tokens  word_count  \\\n",
       "0    True  ['conhecia', 'canal', 'amei', 'personalidade',...          14   \n",
       "1    True    ['amo', 'vamos', 'longos', 'traz', 'maiiissss']           5   \n",
       "2    True  ['julguem', 'achei', 'blusa', 'lindo', 'pele',...           9   \n",
       "3    True  ['realmente', 'pele', 'negra', 'rolacomprei', ...          14   \n",
       "4    True  ['negra', 'gosto', 'contorno', 'blusa', 'chega...          17   \n",
       "\n",
       "   sentimento_text  sentimento_tokens  \n",
       "0              0.0                0.0  \n",
       "1              0.0                0.0  \n",
       "2              0.0                0.0  \n",
       "3              0.0                0.0  \n",
       "4              0.0                0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar coluna de sentimento ao DataFrame\n",
    "df['sentimento_text'] = df['text'].apply(analisar_sentimento_text)\n",
    "df['sentimento_tokens'] = df['tokens'].apply(analisar_sentimento_tokens)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An√°lise de Sentimento dos Coment√°rios (Texto):\n",
      "                                                text  sentimento_text\n",
      "0  N√£o conhecia seu canal e amei sua personalidad...              0.0\n",
      "1             Eu amo v√≠deos longos. E traz maiiissss              0.0\n",
      "2  Me julguem, achei o blush lindo na sua pele. N...              0.0\n",
      "3  Realmente na pele negra n√£o rola...comprei o p...              0.0\n",
      "4  Eu sou negra, gosto do contorno e do blush she...              0.0\n",
      "5                           Nem sabia disso menina üòÇ              0.0\n",
      "6  Mulher qual cor do corretivooooo? Coloca o nom...              0.0\n",
      "7  Amei seus feedbacks, lkkkkk vou comprar s√≥ o c...              0.0\n",
      "8        Maquiagem feita pra pessoas de pele clara..              0.0\n",
      "9  Ju, amei essa maquiagem que voc√™ fez. Linda de...              0.0\n",
      "An√°lise de Sentimento dos Coment√°rios (Tokens):\n",
      "                                              tokens  sentimento_tokens\n",
      "0  ['conhecia', 'canal', 'amei', 'personalidade',...                0.0\n",
      "1    ['amo', 'vamos', 'longos', 'traz', 'maiiissss']                0.0\n",
      "2  ['julguem', 'achei', 'blusa', 'lindo', 'pele',...                0.0\n",
      "3  ['realmente', 'pele', 'negra', 'rolacomprei', ...                0.0\n",
      "4  ['negra', 'gosto', 'contorno', 'blusa', 'chega...                0.0\n",
      "5                       ['sabia', 'disso', 'menina']                0.0\n",
      "6  ['mulher', 'cor', 'corretivooooo', 'coloca', '...                0.0\n",
      "7  ['amei', 'feedbacks', 'lkkkkk', 'vou', 'compra...                0.0\n",
      "8  ['maquinem', 'feita', 'pra', 'pessoas', 'pele'...                0.0\n",
      "9  ['amei', 'maquinem', 'fez', 'linda', 'demais',...                0.0\n"
     ]
    }
   ],
   "source": [
    "# Exibir resultados de sentimento\n",
    "print(\"An√°lise de Sentimento dos Coment√°rios (Texto):\")\n",
    "print(df[['text', 'sentimento_text']].head(10))\n",
    "\n",
    "print(\"An√°lise de Sentimento dos Coment√°rios (Tokens):\")\n",
    "print(df[['tokens', 'sentimento_tokens']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimento M√©dio por Video ID (Texto):\n",
      "      video_id  sentimento_text_medio\n",
      "0  c3Ns-AgD-Vg              -0.009450\n",
      "1  nxdjgqKkOlI               0.001727\n",
      "2  raV8DpfwuR0               0.087165\n",
      "Sentimento M√©dio por Video ID (Tokens):\n",
      "      video_id  sentimento_tokens_medio\n",
      "0  c3Ns-AgD-Vg                 0.022618\n",
      "1  nxdjgqKkOlI                 0.011229\n",
      "2  raV8DpfwuR0                 0.062805\n"
     ]
    }
   ],
   "source": [
    "# Opcional: Agregar resultados de sentimento por video_id ou outra coluna\n",
    "df_sentimento_agrupado_text = df.groupby('video_id')['sentimento_text'].mean().reset_index()\n",
    "df_sentimento_agrupado_text.columns = ['video_id', 'sentimento_text_medio']\n",
    "\n",
    "df_sentimento_agrupado_tokens = df.groupby('video_id')['sentimento_tokens'].mean().reset_index()\n",
    "df_sentimento_agrupado_tokens.columns = ['video_id', 'sentimento_tokens_medio']\n",
    "\n",
    "# Exibir os resultados agregados\n",
    "print(\"Sentimento M√©dio por Video ID (Texto):\")\n",
    "print(df_sentimento_agrupado_text)\n",
    "\n",
    "print(\"Sentimento M√©dio por Video ID (Tokens):\")\n",
    "print(df_sentimento_agrupado_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho da pasta e do arquivo\n",
    "output_dir = 'data'\n",
    "output_file = os.path.join(output_dir, 'youtube_comments_analysis2.csv')\n",
    "\n",
    "# Salvar o DataFrame em um arquivo CSV na pasta 'data'\n",
    "df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
