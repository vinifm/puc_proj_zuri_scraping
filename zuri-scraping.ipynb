{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecionando websites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um dicionário com o site e uma lista de páginas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capricho</td>\n",
       "      <td>https://capricho.abril.com.br/beleza/fenty-bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>https://diadebeaute.com/2024/03/21/lollapalooz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>https://diadebeaute.com/2024/03/15/bases-queri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site                                                url\n",
       "0       capricho  https://capricho.abril.com.br/beleza/fenty-bea...\n",
       "1  dia de beaute  https://diadebeaute.com/2024/03/21/lollapalooz...\n",
       "2  dia de beaute  https://diadebeaute.com/2024/03/15/bases-queri..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_dict = {\n",
    "    'capricho':\n",
    "    [\n",
    "        'https://capricho.abril.com.br/beleza/fenty-beauty-lanca-iluminador-que-promete-favorecer-todos-os-tons-de-pele/'\n",
    "    ]\n",
    "    ,'dia de beaute':\n",
    "    [\n",
    "        'https://diadebeaute.com/2024/03/21/lollapalooza-dicas-para-fazer-sua-make-durar-no-festival/'\n",
    "        ,'https://diadebeaute.com/2024/03/15/bases-queridinhas-dos-maquiadores-das-celebridades/'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Converte o dicionário em uma lista de dicionários\n",
    "data = [{'site': key, 'url': url} for key, urls in url_dict.items() for url in urls]\n",
    "\n",
    "# Transforma em um DataFrame\n",
    "url_df = pd.DataFrame(data)\n",
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vinifm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Puxando stopwords do Natural Language ToolKit (NLTK)\n",
    "nltk.download('stopwords')\n",
    "stopAll = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = bs(content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "def clean_content(pages: list) -> list:\n",
    "    cleaned_content = []\n",
    "    for content in pages:\n",
    "        content = re.sub(r'\\s+', ' ', content)\n",
    "\n",
    "        # remove pontuação\n",
    "        punctuation = string.punctuation + \"-–\"\n",
    "        content = ''.join(char for char in content if char not in punctuation)\n",
    "        cleaned_content.append(content)\n",
    "\n",
    "    return cleaned_content\n",
    "\n",
    "# Adiciona uma coluna no dataframe com o conteúdo da página\n",
    "def get_pages_from_dict(url_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    results = map(get_page, list(url_df['url']))\n",
    "    cleaned_content = clean_content(list(results))\n",
    "    url_df['content'] = cleaned_content\n",
    "\n",
    "    words = []\n",
    "    for page in url_df['content']:\n",
    "        words.append([word.lower() for word in page.split() if word not in stopAll])\n",
    "    url_df['words'] = words\n",
    "\n",
    "    return url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capricho</td>\n",
       "      <td>https://capricho.abril.com.br/beleza/fenty-bea...</td>\n",
       "      <td>Fenty Beauty lança iluminador que promete fav...</td>\n",
       "      <td>[fenty, beauty, lança, iluminador, promete, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>https://diadebeaute.com/2024/03/21/lollapalooz...</td>\n",
       "      <td>Lollapalooza dicas para fazer sua make durar ...</td>\n",
       "      <td>[lollapalooza, dicas, fazer, make, durar, fest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>https://diadebeaute.com/2024/03/15/bases-queri...</td>\n",
       "      <td>Bases queridinhas dos maquiadores das celebri...</td>\n",
       "      <td>[bases, queridinhas, maquiadores, celebridades...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site                                                url  \\\n",
       "0       capricho  https://capricho.abril.com.br/beleza/fenty-bea...   \n",
       "1  dia de beaute  https://diadebeaute.com/2024/03/21/lollapalooz...   \n",
       "2  dia de beaute  https://diadebeaute.com/2024/03/15/bases-queri...   \n",
       "\n",
       "                                             content  \\\n",
       "0   Fenty Beauty lança iluminador que promete fav...   \n",
       "1   Lollapalooza dicas para fazer sua make durar ...   \n",
       "2   Bases queridinhas dos maquiadores das celebri...   \n",
       "\n",
       "                                               words  \n",
       "0  [fenty, beauty, lança, iluminador, promete, fa...  \n",
       "1  [lollapalooza, dicas, fazer, make, durar, fest...  \n",
       "2  [bases, queridinhas, maquiadores, celebridades...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_pages_from_dict(url_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos contabilizar palavras a nível de site e não página, juntamos as listas de palavras de cada página por site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capricho</td>\n",
       "      <td>[fenty, beauty, lança, iluminador, promete, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>[lollapalooza, dicas, fazer, make, durar, fest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site                                              words\n",
       "0       capricho  [fenty, beauty, lança, iluminador, promete, fa...\n",
       "1  dia de beaute  [lollapalooza, dicas, fazer, make, durar, fest..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = df.groupby('site')['words'].agg(lambda x: sum(x, [])).reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando o PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Exit em processos pré-existentes\n",
    "if 'sc' in locals():\n",
    "    sc.stop()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"HelloWorld\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um RDD\n",
    "Um RDD (Resilient Distributed Dataset) no PySpark é a estrutura de dados fundamental do Apache Spark, representando uma coleção distribuída de elementos que podem ser processados em paralelo. Ele é projetado para ser imutável e tolerante a falhas, permitindo operações de transformação (como map e filter) e ações (como count e collect) de forma eficiente e distribuída. Os RDDs podem ser criados a partir de dados presentes no sistema de arquivos local, HDFS, ou outras fontes de dados, e são fundamentais para o processamento e análise de grandes volumes de dados em ambientes distribuíd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capricho</td>\n",
       "      <td>[(fenty, 15), (beauty, 14), (a, 12), (publicid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia de beaute</td>\n",
       "      <td>[(pele, 19), (aqui, 18), (base, 16), (aquibase...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site                                         word_count\n",
       "0       capricho  [(fenty, 15), (beauty, 14), (a, 12), (publicid...\n",
       "1  dia de beaute  [(pele, 19), (aqui, 18), (base, 16), (aquibase..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count = pd.DataFrame()\n",
    "site_list = []\n",
    "word_count_list = []\n",
    "for index, row in grouped_df.iterrows():\n",
    "    rdd = sc.parallelize(row['words'])\n",
    "    counts = rdd.map(lambda word:(word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "    count_list = sorted(counts.collect(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # filtra somente palavras que ocorrem mais de duas vezes\n",
    "    filtered_count = [item for item in count_list if item[1] > 2]\n",
    "    word_count_list.append(filtered_count)\n",
    "    site_list.append(row['site'])\n",
    "\n",
    "df_word_count['site'] = site_list\n",
    "df_word_count['word_count'] = word_count_list\n",
    "\n",
    "df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pele', 19),\n",
       " ('aqui', 18),\n",
       " ('base', 16),\n",
       " ('aquibase', 13),\n",
       " ('make', 13),\n",
       " ('the', 12),\n",
       " ('maquiagem', 12),\n",
       " ('to', 10),\n",
       " ('beauté', 10),\n",
       " ('beleza', 8),\n",
       " ('bem', 8),\n",
       " ('opens', 8),\n",
       " ('in', 8),\n",
       " ('new', 8),\n",
       " ('o', 8),\n",
       " ('on', 8),\n",
       " ('share', 8),\n",
       " ('bases', 8),\n",
       " ('batom', 8),\n",
       " ('cookies', 8),\n",
       " ('terracotta', 7),\n",
       " ('dior', 7),\n",
       " ('vic', 7),\n",
       " ('forever', 7),\n",
       " ('natural', 7),\n",
       " ('sobre', 7),\n",
       " ('backstage', 7),\n",
       " ('…', 6),\n",
       " ('armazenamento', 6),\n",
       " ('acesso', 6),\n",
       " ('guerlain', 6),\n",
       " ('le', 6),\n",
       " ('leia', 6),\n",
       " ('funcional', 6),\n",
       " ('preferences', 6),\n",
       " ('beauty', 6),\n",
       " ('mais', 6),\n",
       " ('preferências', 6),\n",
       " ('dia', 6),\n",
       " ('técnico', 6),\n",
       " ('marketing', 6),\n",
       " ('minutos', 6),\n",
       " ('tudo', 6),\n",
       " ('or', 6),\n",
       " ('manage', 6),\n",
       " ('cobertura', 6),\n",
       " ('produtos', 6),\n",
       " ('skin', 6),\n",
       " ('windowclick', 6),\n",
       " ('site', 6),\n",
       " ('teint', 5),\n",
       " ('necessário', 5),\n",
       " ('sempre', 5),\n",
       " ('lauder', 5),\n",
       " ('cor', 4),\n",
       " ('todosviagemalém', 4),\n",
       " ('delineador', 4),\n",
       " ('storage', 4),\n",
       " ('estatísticas', 4),\n",
       " ('dicas', 4),\n",
       " ('beautéver', 4),\n",
       " ('vários', 4),\n",
       " ('ver', 4),\n",
       " ('lollapalooza', 4),\n",
       " ('comprar', 4),\n",
       " ('skincare', 4),\n",
       " ('marrom', 4),\n",
       " ('tons', 4),\n",
       " ('temporada', 4),\n",
       " ('fins', 4),\n",
       " ('soft', 4),\n",
       " ('vermelho', 4),\n",
       " ('are', 4),\n",
       " ('traz', 4),\n",
       " ('technical', 4),\n",
       " ('multiusocookies', 4),\n",
       " ('not', 4),\n",
       " ('serviço', 4),\n",
       " ('backstagedior', 4),\n",
       " ('vida', 4),\n",
       " ('cabelos', 4),\n",
       " ('maquiadores', 4),\n",
       " ('todoscorpopele', 4),\n",
       " ('post', 4),\n",
       " ('cabelo', 4),\n",
       " ('e', 4),\n",
       " ('finalidade', 4),\n",
       " ('is', 4),\n",
       " ('that', 4),\n",
       " ('purposes', 4),\n",
       " ('oleosapele', 4),\n",
       " ('ddb', 4),\n",
       " ('160524', 4),\n",
       " ('quem', 4),\n",
       " ('access', 4),\n",
       " ('bastão', 4),\n",
       " ('contato', 4),\n",
       " ('todos', 4),\n",
       " ('época', 4),\n",
       " ('líquido', 4),\n",
       " ('consentimento', 4),\n",
       " ('durar', 4),\n",
       " ('email', 4),\n",
       " ('protagonista', 4),\n",
       " ('2', 4),\n",
       " ('lançamento', 4),\n",
       " ('melhor', 4),\n",
       " ('falar', 4),\n",
       " ('usuário', 4),\n",
       " ('title', 4),\n",
       " ('fazer', 4),\n",
       " ('todosperfumerelatosrituaissaúdebanhobeleza', 4),\n",
       " ('final', 4),\n",
       " ('double', 4),\n",
       " ('pinterest', 3),\n",
       " ('undercover', 3),\n",
       " ('saiba', 3),\n",
       " ('queridinhas', 3),\n",
       " ('se', 3),\n",
       " ('a', 3),\n",
       " ('glow', 3),\n",
       " ('“a', 3),\n",
       " ('fina', 3),\n",
       " ('olhos', 3),\n",
       " ('wear', 3),\n",
       " ('produto', 3),\n",
       " ('brasil', 3),\n",
       " ('teintguerlain', 3),\n",
       " ('baims', 3),\n",
       " ('festival', 3),\n",
       " ('nesse', 3),\n",
       " ('fim', 3),\n",
       " ('aí', 3),\n",
       " ('momento', 3),\n",
       " ('estée', 3),\n",
       " ('penteados', 3),\n",
       " ('primeiro', 3),\n",
       " ('perfeita', 3),\n",
       " ('acabamento', 3),\n",
       " ('textura', 3),\n",
       " ('líquida', 3),\n",
       " ('inspiração', 3),\n",
       " ('mate', 3),\n",
       " ('pó', 3),\n",
       " ('lábios', 3),\n",
       " ('durabilidade', 3),\n",
       " ('conheça', 3),\n",
       " ('chanel', 3)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_count['word_count'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
